{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98c95a0c-bf60-4486-baf3-c1fbb7b0cd89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# link for below exercise\n",
    "# https://www.geeksforgeeks.org/pyspark-window-functions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1d631b0-cc59-4531-a734-ec03404e0e55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12992/3153844193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Pyspark SQL Like Functions').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68ed33a1-ffe6-4ffc-928f-94659a1dc1d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales = r\"/user/storage/sales.csv\"\n",
    "products = r\"/user/storage/products.csv\"\n",
    "sellers = r\"/user/storage/sellers.csv\"\n",
    "sales_df = spark.read.csv(sales, header=True, inferSchema=True)\n",
    "products_df = spark.read.csv(products, header=True, inferSchema=True)\n",
    "sellers_df = spark.read.csv(sellers, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4215f59b-15b9-420d-9e99-6fd145dfbf1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0ce15af1-0680-4728-8f70-03164f47fd8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample data for dataframe\n",
    "sampleData = ((\"Ram\", 28, \"Sales\", 3000),\n",
    "              (\"Meena\", 33, \"Sales\", 4600),\n",
    "              (\"Robin\", 40, \"Sales\", 4100),\n",
    "              (\"Kunal\", 25, \"Finance\", 3000),\n",
    "              (\"Ram\", 28, \"Sales\", 3000),\n",
    "              (\"Srishti\", 46, \"Management\", 3300),\n",
    "              (\"Jeny\", 26, \"Finance\", 3900),\n",
    "              (\"Hitesh\", 30, \"Marketing\", 3000),\n",
    "              (\"Kailash\", 29, \"Marketing\", 2000),\n",
    "              (\"Sharad\", 39, \"Sales\", 4100)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e53b9ab8-eabd-4b6c-a1cf-ce47135d3ae4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Ram', 28, 'Sales', 3000),\n",
       " ('Meena', 33, 'Sales', 4600),\n",
       " ('Robin', 40, 'Sales', 4100),\n",
       " ('Kunal', 25, 'Finance', 3000),\n",
       " ('Ram', 28, 'Sales', 3000),\n",
       " ('Srishti', 46, 'Management', 3300),\n",
       " ('Jeny', 26, 'Finance', 3900),\n",
       " ('Hitesh', 30, 'Marketing', 3000),\n",
       " ('Kailash', 29, 'Marketing', 2000),\n",
       " ('Sharad', 39, 'Sales', 4100))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7f02a58c-1b83-4ed2-94a7-33f11144cf67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# column names for dataframe\n",
    "columns = [\"Employee_Name\", \"Age\",\n",
    "           \"Department\", \"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3ff3ceb0-968f-44b7-afe9-818251092a23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Employee_Name', 'Age', 'Department', 'Salary']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1cab6765-d90f-410f-b709-05e474545ff3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data = sampleData, schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6b4c2e0a-6bc3-4f47-b1ec-a6f807578c02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+\n",
      "|Employee_Name|Age|Department|Salary|\n",
      "+-------------+---+----------+------+\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|        Meena| 33|     Sales|  4600|\n",
      "|        Robin| 40|     Sales|  4100|\n",
      "|        Kunal| 25|   Finance|  3000|\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|      Srishti| 46|Management|  3300|\n",
      "|         Jeny| 26|   Finance|  3900|\n",
      "|       Hitesh| 30| Marketing|  3000|\n",
      "|      Kailash| 29| Marketing|  2000|\n",
      "|       Sharad| 39|     Sales|  4100|\n",
      "+-------------+---+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "17878574-e24a-4ed4-83ec-92978c2d2543",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# importing Window from pyspark.sql.window\n",
    " \n",
    "# creating a window\n",
    "# partition of dataframe\n",
    "windowPartition = Window.partitionBy(\"Department\").orderBy(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f534bfca-b9f5-4076-9537-fa7b9ad7a82c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+---------+\n",
      "|Employee_Name|Age|Department|Salary|cume_dist|\n",
      "+-------------+---+----------+------+---------+\n",
      "|          Ram| 28|     Sales|  3000|      0.4|\n",
      "|          Ram| 28|     Sales|  3000|      0.4|\n",
      "|        Meena| 33|     Sales|  4600|      0.6|\n",
      "|       Sharad| 39|     Sales|  4100|      0.8|\n",
      "|        Robin| 40|     Sales|  4100|      1.0|\n",
      "|        Kunal| 25|   Finance|  3000|      0.5|\n",
      "|         Jeny| 26|   Finance|  3900|      1.0|\n",
      "|      Srishti| 46|Management|  3300|      1.0|\n",
      "|      Kailash| 29| Marketing|  2000|      0.5|\n",
      "|       Hitesh| 30| Marketing|  3000|      1.0|\n",
      "+-------------+---+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cume_dist() window function is used to get the cumulative distribution within a window partition. It is similar to CUME_DIST in SQL\n",
    "\n",
    "df.withColumn('cume_dist', cume_dist().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6b1834a9-15b1-4d9f-af94-1d2e861cae98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+\n",
      "|Employee_Name|Age|Department|Salary|\n",
      "+-------------+---+----------+------+\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|        Meena| 33|     Sales|  4600|\n",
      "|        Robin| 40|     Sales|  4100|\n",
      "|        Kunal| 25|   Finance|  3000|\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|      Srishti| 46|Management|  3300|\n",
      "|         Jeny| 26|   Finance|  3900|\n",
      "|       Hitesh| 30| Marketing|  3000|\n",
      "|      Kailash| 29| Marketing|  2000|\n",
      "|       Sharad| 39|     Sales|  4100|\n",
      "+-------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# registering the df dataframe as a temp table\n",
    "df.registerTempTable('emp_data')\n",
    "spark.sql(\"select * from emp_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d4d9b5a9-363f-49c7-a9a3-9b3c61764eec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+---+\n",
      "|Employee_Name|Age|Department|Salary| rn|\n",
      "+-------------+---+----------+------+---+\n",
      "|          Ram| 28|     Sales|  3000|0.4|\n",
      "|          Ram| 28|     Sales|  3000|0.4|\n",
      "|        Meena| 33|     Sales|  4600|0.6|\n",
      "|       Sharad| 39|     Sales|  4100|0.8|\n",
      "|        Robin| 40|     Sales|  4100|1.0|\n",
      "|        Kunal| 25|   Finance|  3000|0.5|\n",
      "|         Jeny| 26|   Finance|  3900|1.0|\n",
      "|      Srishti| 46|Management|  3300|1.0|\n",
      "|      Kailash| 29| Marketing|  2000|0.5|\n",
      "|       Hitesh| 30| Marketing|  3000|1.0|\n",
      "+-------------+---+----------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementation of window funtion in SQL\n",
    "\n",
    "# row_number()\n",
    "# spark.sql(\"\"\"select *, row_number() over(partition by Department order by Age) as rn from emp_data\"\"\").show()\n",
    "\n",
    "# cum_dist()\n",
    "spark.sql(\"\"\"select *, cume_dist() over(partition by Department order by Age) as rn from emp_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ebf93496-785e-47ea-bd9c-5eec686a2de0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary| lag|\n",
      "+-------------+---+----------+------+----+\n",
      "|          Ram| 28|     Sales|  3000|null|\n",
      "|          Ram| 28|     Sales|  3000|3000|\n",
      "|        Meena| 33|     Sales|  4600|3000|\n",
      "|       Sharad| 39|     Sales|  4100|4600|\n",
      "|        Robin| 40|     Sales|  4100|4100|\n",
      "|        Kunal| 25|   Finance|  3000|null|\n",
      "|         Jeny| 26|   Finance|  3900|3000|\n",
      "|      Srishti| 46|Management|  3300|null|\n",
      "|      Kailash| 29| Marketing|  2000|null|\n",
      "|       Hitesh| 30| Marketing|  3000|2000|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lag() function\n",
    "\n",
    "# A lag() function is used to access previous rowsâ€™ data as per the defined offset value in the function\n",
    "\n",
    "df.withColumn('lag', lag('salary', 1).over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b3268696-c4cc-4781-95cf-a8d497a27cc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary|  rn|\n",
      "+-------------+---+----------+------+----+\n",
      "|          Ram| 28|     Sales|  3000|null|\n",
      "|          Ram| 28|     Sales|  3000|3000|\n",
      "|        Meena| 33|     Sales|  4600|3000|\n",
      "|       Sharad| 39|     Sales|  4100|4600|\n",
      "|        Robin| 40|     Sales|  4100|4100|\n",
      "|        Kunal| 25|   Finance|  3000|null|\n",
      "|         Jeny| 26|   Finance|  3900|3000|\n",
      "|      Srishti| 46|Management|  3300|null|\n",
      "|      Kailash| 29| Marketing|  2000|null|\n",
      "|       Hitesh| 30| Marketing|  3000|2000|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementation in SQL\n",
    "\n",
    "spark.sql(\"\"\"select *, lag(salary,1) over(partition by Department order by Age) as rn from emp_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "51b14d14-2083-48fa-934c-1666d1323150",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary| lag|\n",
      "+-------------+---+----------+------+----+\n",
      "|          Ram| 28|     Sales|  3000|4600|\n",
      "|          Ram| 28|     Sales|  3000|4100|\n",
      "|        Meena| 33|     Sales|  4600|4100|\n",
      "|       Sharad| 39|     Sales|  4100|null|\n",
      "|        Robin| 40|     Sales|  4100|null|\n",
      "|        Kunal| 25|   Finance|  3000|null|\n",
      "|         Jeny| 26|   Finance|  3900|null|\n",
      "|      Srishti| 46|Management|  3300|null|\n",
      "|      Kailash| 29| Marketing|  2000|null|\n",
      "|       Hitesh| 30| Marketing|  3000|null|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A lead() function is used to access next rows data as per the defined offset value in the function.\n",
    "\n",
    "df.withColumn('lag', lead('salary', 2).over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4e4297e-cf31-4322-a9a9-a0f1f4c4225c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# using percent function\n",
    "\n",
    "# df.withColumn('percent_rank', percent_rank().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0dec7eb-fb14-4143-97a1-2f863329a05e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary|  rn|\n",
      "+-------------+---+----------+------+----+\n",
      "|          Ram| 28|     Sales|  3000|3000|\n",
      "|          Ram| 28|     Sales|  3000|4600|\n",
      "|        Meena| 33|     Sales|  4600|4100|\n",
      "|       Sharad| 39|     Sales|  4100|4100|\n",
      "|        Robin| 40|     Sales|  4100|null|\n",
      "|        Kunal| 25|   Finance|  3000|3900|\n",
      "|         Jeny| 26|   Finance|  3900|null|\n",
      "|      Srishti| 46|Management|  3300|null|\n",
      "|      Kailash| 29| Marketing|  2000|3000|\n",
      "|       Hitesh| 30| Marketing|  3000|null|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementation in SQL\n",
    "\n",
    "spark.sql(\"\"\"select *, lead(salary,1) over(partition by Department order by Age) as rn from emp_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df26d2cc-fb8a-4a45-990c-48b05d4c04ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Ranking functions\n",
    "\n",
    "# sample data for dataframe\n",
    "sampleData = ((101, \"Ram\", \"Biology\", 80),\n",
    "              (103, \"Meena\", \"Social Science\", 78),\n",
    "              (104, \"Robin\", \"Sanskrit\", 58),\n",
    "              (102, \"Kunal\", \"Phisycs\", 89),\n",
    "              (101, \"Ram\", \"Biology\", 80),\n",
    "              (106, \"Srishti\", \"Maths\", 70),\n",
    "              (108, \"Jeny\", \"Physics\", 75),\n",
    "              (107, \"Hitesh\", \"Maths\", 88),\n",
    "              (109, \"Kailash\", \"Maths\", 90),\n",
    "              (105, \"Sharad\", \"Social Science\", 84)\n",
    "              )\n",
    " \n",
    "# column names for dataframe\n",
    "columns = [\"Roll_No\", \"Student_Name\", \"Subject\", \"Marks\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1bf27bee-c78f-442d-a18d-92d510217ebe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+\n",
      "|Roll_No|Student_Name|       Subject|Marks|\n",
      "+-------+------------+--------------+-----+\n",
      "|    101|         Ram|       Biology|   80|\n",
      "|    103|       Meena|Social Science|   78|\n",
      "|    104|       Robin|      Sanskrit|   58|\n",
      "|    102|       Kunal|       Phisycs|   89|\n",
      "|    101|         Ram|       Biology|   80|\n",
      "|    106|     Srishti|         Maths|   70|\n",
      "|    108|        Jeny|       Physics|   75|\n",
      "|    107|      Hitesh|         Maths|   88|\n",
      "|    109|     Kailash|         Maths|   90|\n",
      "|    105|      Sharad|Social Science|   84|\n",
      "+-------+------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(data = sampleData, schema=columns)\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "86806ba8-a66c-4930-9422-a0dbefed7fc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "windowPartition = Window.partitionBy(\"Subject\").orderBy(col(\"Marks\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "077e13b5-0a7c-4876-a434-7e462b9e22ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+-------+\n",
      "|Roll_No|Student_Name|       Subject|Marks|row_num|\n",
      "+-------+------------+--------------+-----+-------+\n",
      "|    102|       Kunal|       Phisycs|   89|      1|\n",
      "|    105|      Sharad|Social Science|   84|      1|\n",
      "|    103|       Meena|Social Science|   78|      2|\n",
      "|    109|     Kailash|         Maths|   90|      1|\n",
      "|    107|      Hitesh|         Maths|   88|      2|\n",
      "|    106|     Srishti|         Maths|   70|      3|\n",
      "|    108|        Jeny|       Physics|   75|      1|\n",
      "|    104|       Robin|      Sanskrit|   58|      1|\n",
      "|    101|         Ram|       Biology|   80|      1|\n",
      "|    101|         Ram|       Biology|   80|      2|\n",
      "+-------+------------+--------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using row_number().\n",
    "# row_number() function is used to gives a sequential number to each row present in the table\n",
    "\n",
    "df2.withColumn('row_num', row_number().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ae99e639-3abf-4daf-91a1-de1bbbe88dc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+-------+\n",
      "|Roll_No|Student_Name|       Subject|Marks|row_num|\n",
      "+-------+------------+--------------+-----+-------+\n",
      "|    102|       Kunal|       Phisycs|   89|      1|\n",
      "|    105|      Sharad|Social Science|   84|      1|\n",
      "|    103|       Meena|Social Science|   78|      2|\n",
      "|    109|     Kailash|         Maths|   90|      1|\n",
      "|    107|      Hitesh|         Maths|   88|      2|\n",
      "|    106|     Srishti|         Maths|   70|      3|\n",
      "|    108|        Jeny|       Physics|   75|      1|\n",
      "|    104|       Robin|      Sanskrit|   58|      1|\n",
      "|    101|         Ram|       Biology|   80|      1|\n",
      "|    101|         Ram|       Biology|   80|      2|\n",
      "+-------+------------+--------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the top record from each department\n",
    "\n",
    "df2.withColumn('row_num', row_number().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45776bfd-e1aa-4b7c-af0c-5ef429ff7efa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+----+\n",
      "|Roll_No|Student_Name|       Subject|Marks|rank|\n",
      "+-------+------------+--------------+-----+----+\n",
      "|    102|       Kunal|       Phisycs|   89|   1|\n",
      "|    105|      Sharad|Social Science|   84|   1|\n",
      "|    103|       Meena|Social Science|   78|   2|\n",
      "|    109|     Kailash|         Maths|   90|   1|\n",
      "|    107|      Hitesh|         Maths|   88|   2|\n",
      "|    106|     Srishti|         Maths|   70|   3|\n",
      "|    108|        Jeny|       Physics|   75|   1|\n",
      "|    104|       Robin|      Sanskrit|   58|   1|\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "+-------+------------+--------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using rank()\n",
    "# The rank function is used to give ranks to rows specified in the window partition.\n",
    "\n",
    "df2.withColumn('rank', rank().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7783c8c3-d874-400c-a4fd-cbc6891f9837",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+------------+\n",
      "|Roll_No|Student_Name|       Subject|Marks|percent_rank|\n",
      "+-------+------------+--------------+-----+------------+\n",
      "|    102|       Kunal|       Phisycs|   89|         0.0|\n",
      "|    105|      Sharad|Social Science|   84|         0.0|\n",
      "|    103|       Meena|Social Science|   78|         1.0|\n",
      "|    109|     Kailash|         Maths|   90|         0.0|\n",
      "|    107|      Hitesh|         Maths|   88|         0.5|\n",
      "|    106|     Srishti|         Maths|   70|         1.0|\n",
      "|    108|        Jeny|       Physics|   75|         0.0|\n",
      "|    104|       Robin|      Sanskrit|   58|         0.0|\n",
      "|    101|         Ram|       Biology|   80|         0.0|\n",
      "|    101|         Ram|       Biology|   80|         0.0|\n",
      "+-------+------------+--------------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using percent_rank()\n",
    "# This function is similar to rank() function. It also provides rank to rows but in a percentile format\n",
    "\n",
    "df2.withColumn('percent_rank', percent_rank().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bebd904c-5db0-4283-a7e0-8b80ff4b6e2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+----------+\n",
      "|Roll_No|Student_Name|       Subject|Marks|dense_rank|\n",
      "+-------+------------+--------------+-----+----------+\n",
      "|    102|       Kunal|       Phisycs|   89|         1|\n",
      "|    105|      Sharad|Social Science|   84|         1|\n",
      "|    103|       Meena|Social Science|   78|         2|\n",
      "|    109|     Kailash|         Maths|   90|         1|\n",
      "|    107|      Hitesh|         Maths|   88|         2|\n",
      "|    106|     Srishti|         Maths|   70|         3|\n",
      "|    108|        Jeny|       Physics|   75|         1|\n",
      "|    104|       Robin|      Sanskrit|   58|         1|\n",
      "|    101|         Ram|       Biology|   80|         1|\n",
      "|    101|         Ram|       Biology|   80|         1|\n",
      "+-------+------------+--------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using dense_rank()\n",
    "# This function is used to get the rank of each row in the form of row numbers. This is similar to rank() function, there is only one difference the rank function leaves gaps in rank when there are ties\n",
    "\n",
    "df2.withColumn('dense_rank', dense_rank().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad1a1c90-6841-4602-abdf-9f0905ca67f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate function\n",
    "\n",
    "# AVERAGE, SUM, MIN, MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "081ed445-f973-4f4d-bcff-06dc38f80fa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sample data for dataframe\n",
    "sampleData = ((\"Ram\", \"Sales\", 3000),\n",
    "              (\"Meena\", \"Sales\", 4600),\n",
    "              (\"Robin\", \"Sales\", 4100),\n",
    "              (\"Kunal\", \"Finance\", 3000),\n",
    "              (\"Ram\", \"Sales\", 3000),\n",
    "              (\"Srishti\", \"Management\", 3300),\n",
    "              (\"Jeny\", \"Finance\", 3900),\n",
    "              (\"Hitesh\", \"Marketing\", 3000),\n",
    "              (\"Kailash\", \"Marketing\", 2000),\n",
    "              (\"Sharad\", \"Sales\", 4100)\n",
    "              )\n",
    " \n",
    "# column names for dataframe\n",
    "columns = [\"Employee_Name\", \"Department\", \"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "64be7e05-3c1d-413b-b089-b5e51c195e59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame(data = sampleData, schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fad852d9-196d-4f15-89b7-618d8cae0b92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|Employee_Name|Department|Salary|\n",
      "+-------------+----------+------+\n",
      "|          Ram|     Sales|  3000|\n",
      "|        Meena|     Sales|  4600|\n",
      "|        Robin|     Sales|  4100|\n",
      "|        Kunal|   Finance|  3000|\n",
      "|          Ram|     Sales|  3000|\n",
      "|      Srishti|Management|  3300|\n",
      "|         Jeny|   Finance|  3900|\n",
      "|       Hitesh| Marketing|  3000|\n",
      "|      Kailash| Marketing|  2000|\n",
      "|       Sharad|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cb6a2e69-3b23-4042-8fec-d449b55a2994",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "windowPartitionAgg  = Window.partitionBy(\"Department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "78f9b8a3-bdd4-4536-a0c0-b8f0f9762dd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+------+\n",
      "|Employee_Name|Department|Salary|   avg|\n",
      "+-------------+----------+------+------+\n",
      "|       Sharad|     Sales|  4100|3760.0|\n",
      "|          Ram|     Sales|  3000|3760.0|\n",
      "|        Meena|     Sales|  4600|3760.0|\n",
      "|        Robin|     Sales|  4100|3760.0|\n",
      "|          Ram|     Sales|  3000|3760.0|\n",
      "|        Kunal|   Finance|  3000|3450.0|\n",
      "|         Jeny|   Finance|  3900|3450.0|\n",
      "|      Srishti|Management|  3300|3300.0|\n",
      "|       Hitesh| Marketing|  3000|2500.0|\n",
      "|      Kailash| Marketing|  2000|2500.0|\n",
      "+-------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg()\n",
    "\n",
    "df3.withColumn('avg', avg(col('salary')).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c8e299a3-ede6-4251-8503-674607cd17c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|Employee_Name|Department|Salary|  avg|\n",
      "+-------------+----------+------+-----+\n",
      "|       Sharad|     Sales|  4100|18800|\n",
      "|          Ram|     Sales|  3000|18800|\n",
      "|        Meena|     Sales|  4600|18800|\n",
      "|        Robin|     Sales|  4100|18800|\n",
      "|          Ram|     Sales|  3000|18800|\n",
      "|         Jeny|   Finance|  3900| 6900|\n",
      "|        Kunal|   Finance|  3000| 6900|\n",
      "|      Srishti|Management|  3300| 3300|\n",
      "|       Hitesh| Marketing|  3000| 5000|\n",
      "|      Kailash| Marketing|  2000| 5000|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sum()\n",
    "\n",
    "df3.withColumn('avg', sum(col('salary')).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdb16682-1944-4156-a580-e5da51e0e0d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|Employee_Name|Department|Salary| avg|\n",
      "+-------------+----------+------+----+\n",
      "|          Ram|     Sales|  3000|3000|\n",
      "|        Meena|     Sales|  4600|3000|\n",
      "|        Robin|     Sales|  4100|3000|\n",
      "|          Ram|     Sales|  3000|3000|\n",
      "|       Sharad|     Sales|  4100|3000|\n",
      "|         Jeny|   Finance|  3900|3000|\n",
      "|        Kunal|   Finance|  3000|3000|\n",
      "|      Srishti|Management|  3300|3300|\n",
      "|       Hitesh| Marketing|  3000|2000|\n",
      "|      Kailash| Marketing|  2000|2000|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min()\n",
    "\n",
    "df3.withColumn('avg', min(col('salary')).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b2ca88d-d13f-4f2f-824a-fc291b48e500",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|Employee_Name|Department|Salary| avg|\n",
      "+-------------+----------+------+----+\n",
      "|          Ram|     Sales|  3000|4600|\n",
      "|        Meena|     Sales|  4600|4600|\n",
      "|        Robin|     Sales|  4100|4600|\n",
      "|          Ram|     Sales|  3000|4600|\n",
      "|       Sharad|     Sales|  4100|4600|\n",
      "|         Jeny|   Finance|  3900|3900|\n",
      "|        Kunal|   Finance|  3000|3900|\n",
      "|      Srishti|Management|  3300|3300|\n",
      "|       Hitesh| Marketing|  3000|3000|\n",
      "|      Kailash| Marketing|  2000|3000|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max()\n",
    "\n",
    "df3.withColumn('avg', max(col('salary')).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b9b4814-7815-4f43-a4a8-c2cbe5e5fbb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark_sql_like_functions",
   "notebookOrigID": 1103407647421281,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
