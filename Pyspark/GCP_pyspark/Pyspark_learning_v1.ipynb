{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.conf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9304/560497365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mformat_number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyspark\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRDDBarrier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkFiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark.conf'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import format_number\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession.builder.appName(\"Notes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sc.parallelize(['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = spark.read.json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spark.read.option('multiline', 'true').json('test copy.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "| mission|   name|\n",
      "+--------+-------+\n",
      "|learning|Pyspark|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|nested|\n",
      "+------+\n",
      "|{1, 2}|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.select('nested').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## workin on Walmart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walmart = spark.read.format('csv').option('header', 'true').option('inferSchema','true').load('walmart_stock_data.csv')\n",
    "\n",
    "walmart = spark.read.csv('walmart_stock_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+---------+-------------+\n",
      "|      Date|  Open|  High|   Low| Close|   Volume|modified_date|\n",
      "+----------+------+------+------+------+---------+-------------+\n",
      "|11/23/2021|144.25|145.98|143.25|145.81|9,972,448|         null|\n",
      "|11/22/2021|142.66|145.36| 142.0|144.78|9,716,788|         null|\n",
      "+----------+------+------+------+------+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.withColumn('modified_date', f.to_date(f.col(\"Date\"),\"MM-dd-yyyy\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|      date| mod|\n",
      "+----------+----+\n",
      "|11/23/2021|null|\n",
      "+----------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "walmart.select('date', f.to_date(f.col('date'), 'yyyy/mm/dd').alias('mod') ).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+---------+\n",
      "|      Date|  Open|  High|   Low| Close|   Volume|\n",
      "+----------+------+------+------+------+---------+\n",
      "|11/23/2021|144.25|145.98|143.25|145.81|9,972,448|\n",
      "+----------+------+------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.filter('open == 144.25').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "|summary|      Date|              Open|              High|               Low|             Close|    Volume|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "|  count|        22|                22|                22|                22|                22|        22|\n",
      "|   mean|      null|147.77454545454546|148.67954545454543|146.64181818181817|147.60590909090908|      null|\n",
      "| stddev|      null| 2.869992081078725| 2.529469127952351| 3.022299087597338|2.8208098450299897|      null|\n",
      "|    min|10/25/2021|            142.14|            143.29|            140.86|            141.94|11,038,740|\n",
      "|    max|11/23/2021|             152.0|             152.0|            149.83|            151.28| 9,972,448|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = walmart.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "|summary|      Date|              Open|              High|               Low|             Close|    Volume|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "|  count|        22|                22|                22|                22|                22|        22|\n",
      "|   mean|      null|147.77454545454546|148.67954545454543|146.64181818181817|147.60590909090908|      null|\n",
      "| stddev|      null| 2.869992081078725| 2.529469127952351| 3.022299087597338|2.8208098450299897|      null|\n",
      "|    min|10/25/2021|            142.14|            143.29|            140.86|            141.94|11,038,740|\n",
      "|    max|11/23/2021|             152.0|             152.0|            149.83|            151.28| 9,972,448|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|summary|  open|\n",
      "+-------+------+\n",
      "|  count| 22.00|\n",
      "|   mean|147.77|\n",
      "| stddev|  2.87|\n",
      "|    min|142.14|\n",
      "|    max|152.00|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.select('summary',\n",
    "    format_number(summary['Open'].cast('float'),2).alias('open')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+----------+\n",
      "|      Date|  Open|  High|   Low| Close|    Volume|\n",
      "+----------+------+------+------+------+----------+\n",
      "|11/23/2021|144.25|145.98|143.25|145.81| 9,972,448|\n",
      "|11/22/2021|142.66|145.36| 142.0|144.78| 9,716,788|\n",
      "|11/19/2021|143.62| 144.0|141.94|142.39| 9,380,728|\n",
      "|11/18/2021|142.14|143.29|140.86|143.16| 8,135,824|\n",
      "|11/17/2021|143.16|144.72|141.82|141.94|11,038,740|\n",
      "+----------+------+------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(walmart.orderBy(walmart.High.desc()).select('Date').head(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|       Min|       Max|\n",
      "+----------+----------+\n",
      "|10/25/2021|11/23/2021|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.select(f.min('Date').alias('Min'), f.max('Date').alias('Max')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.withColumn('Year', f.year(walmart.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+------+----------+----+\n",
      "|      Date|  Open|  High|   Low| Close|    Volume|Year|\n",
      "+----------+------+------+------+------+----------+----+\n",
      "|11/23/2021|144.25|145.98|143.25|145.81| 9,972,448|null|\n",
      "|11/22/2021|142.66|145.36| 142.0|144.78| 9,716,788|null|\n",
      "|11/19/2021|143.62| 144.0|141.94|142.39| 9,380,728|null|\n",
      "|11/18/2021|142.14|143.29|140.86|143.16| 8,135,824|null|\n",
      "|11/17/2021|143.16|144.72|141.82|141.94|11,038,740|null|\n",
      "+----------+------+------+------+------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "walmart.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.createDataFrame([[\"02-03-2013\"],[\"05-06-2023\"]],[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+--------+\n",
      "|empid|  name|age|location|\n",
      "+-----+------+---+--------+\n",
      "|    1|lokesh| 25|     ctr|\n",
      "|    2| madhu| 23|     tpt|\n",
      "+-----+------+---+--------+\n",
      "\n",
      "+-----+------+---+--------+\n",
      "|empid|  name|age|location|\n",
      "+-----+------+---+--------+\n",
      "|    1|lokesh| 24|     ctr|\n",
      "|    2| madhu| 23|     tpt|\n",
      "|    3| ressh| 23|     vlr|\n",
      "+-----+------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_f1 = spark.read.csv('file1.csv', header=True, inferSchema=True)\n",
    "df_f2 = spark.read.csv('file2.csv', header=True, inferSchema=True)\n",
    "df_f1.show()\n",
    "df_f2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+--------+\n",
      "|empid|  name|age|location|\n",
      "+-----+------+---+--------+\n",
      "|    1|lokesh| 24|     ctr|\n",
      "|    3| ressh| 23|     vlr|\n",
      "|    2| madhu| 23|     tpt|\n",
      "+-----+------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['age', 'location']\n",
    "df_f2.alias('a').join(\n",
    "    df_f2.alias('b'), on=['empid', 'name'], how='outer'\n",
    ").select('empid', 'name', *(f.coalesce('b.'+col, 'a.'+col).alias(col) for col in cols)) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a542ca580817fc4dd55327026e074e2fa0cd470fc5dee9350c2d8b13822db8d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
